---
title: "STAT 385 Statistics Programming Methods - Fall 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Week 8 Notes
### Created by Christopher Kinson


***


## Things Covered in this Week's Notes

- What is data

- Importing data

- Data wrangling


***

## What is data
Do you think about data? If not, you should try it out. Think about how data came to be, the ways in which it can exist (or be), what was or is its plan, what do we want to do with it, and how we envision or plan for it to be used later. Data is information at its most simplest definition. This information or data can be collected and stored in various ways. Data can be a table of values, a book, a picture, a tweet, a time stamp, a tool, and so many other things.

Data sets, as we often imagine, are organized tabular forms of information with fields or columns and observations or rows. Here's an example of a data set you have probably heard of before:

![](https://uofi.box.com/shared/static/475yspf8rvae1oax8letjv89r1eeiq9h.png)

Did you consider that the image itself is also a data set? It contains information about its size (pixels), contents, and other features. Below are other forms and structures of data we may need to deal with.

### Structured data
Structured data sets are simply files with records (observations) and fields (columns). The fields are often organized in a particular way either with delimiters or set with fixed-width. Most data sets that you deal with in the STAT major are structured data.

Delimiters are specific characters used to separate fields of information such as commas, colons, spaces, tabs, and even pipes. In Europe, semi-colon is a typical delimiter.

When information is set to a fixed width, fields can essentially be counted by the eye and are not required to be fixed for all columns; only that each column has its own fixed width.

These structured data sets are usually saved (or named) with a file extension, and the file extension serves as a clue for the way the file is delimited or organized. However, a file name can have no extensions or even multiple extensions such as .nb.html and .tar.gz.

Here's a table of common file formats, delimiters, and extensions for data we might work with. What's represented here are not strict rules.

Format | Delimiter | Extension
---|---|---
comma-separated | \, | .csv
tab-delimited or tab-separated | \\t | .txt or .tsv
fixed-width | field width | .dat or .txt
delimited or delimiter-separated | \| or \: or \; | .txt or .csv or .dat

Below is a .csv file.
```
Victim_Name, Age, Race_Ethnicity, City, State, Date_of_Death, Before_Police_Arrived, Officer, Police_Department, Armed_Before_Police_Arrived, Officer_Charged, Officer_Race_Ethnicity
Rayshard Brooks, 27, Black, Atlanta, GA, 06-12-2020, Sleeping in car at Wendy's, Garret Rolfe, Atlanta Police Department, N, Y, White
Dominique Clayton, 32, Black, Oxford, MS, 05-19-2019, Sleeping in bed at home, Matthew Kinne, Oxford Police Department, N, Y, White
Michael Lorenzo Dean, 28, Black, Temple, TX, 12-02-2020, Driving in car on road, Carmen DeCruz, Temple Police Department, N, Y, Latinx
George Floyd, 46, Black, Minneapolis, MN, 05-25-2020, Driving in car from store, Derek Chauvin, Minneapolis Police Department, N, Y, White
Atatiana Jefferson, 28, Black, Fort Worth, TX, 10-12-2019, Babysitting nephew at home, Aaron Dean, Fort Worth Police Department, Y, Y, White
Sean Monterrosa, 22, Latinx, Vallejo, CA, 06-02-2020, In Walgreens parking lot, Jarrett Tonn, Vallejo Police Department, N, N, White
Eric Reason, 38, Black, Vallejo, CA, 11-10-2019, In JJ's Fish and Chicken parking lot, Virgil Thomas, Richmond Police Department, Y, N, Black
Breonna Taylor, 26, Black, Louisville, KY, 03-13-2020, Sleeping in bed at home, Brett Hankison, Louisville Metro Police Department, N, N, White
```

Data may be organized and delimited and it might be helpful to check that the data we imported honors that organization. One way to do that is to check the descriptor portion of the data (e.g. structure and mode of the data with `str()` and `mode()`). The descriptor portion might also be known as the data's contents, structure, or summary. In addition to the descriptor portion, we might just want to see the data by printing it out. Checking both the printout and the descriptor portion can provide a quick verification that the data is imported successfully (assuming no processing or syntax errors have been detected).

Below is an image of the print out of the .csv file and its descriptor portion.
![](https://uofi.box.com/shared/static/hfjc7a78f7towkxcy7w2zl5voie5x0un.png)


### Semi-structured data
Semi-structured data may be files that are organized with tags or attributes but the information is in human-readable text; giving rise to its "semi-structured" name. Some common examples of semi-structured data are stored in JSON, GeoJSON, XML, and XLSX. These file formats are quite popular for web development and often created for communicating between the web and applications. Due to the semi-structure, accessing and importing these files may require special packages and tools inside (or outside) of R.

Below is a JSON data file.
```
[{"Victim_Name":"Rayshard Brooks","Age":27,"Race_Ethnicity":"Black","City":"Atlanta","State":"GA","Date_of_Death":"06-12-2020","Before_Police_Arrived":"Sleeping in car at Wendy's","Officer":"Garret Rolfe","Police_Department":"Atlanta Police Department","Armed_Before_Police_Arrived":"N","Officer_Charged":"Y","Officer_Race_Ethnicity":"White"},{"Victim_Name":"Dominique Clayton","Age":32,"Race_Ethnicity":"Black","City":"Oxford","State":"MS","Date_of_Death":"05-19-2019","Before_Police_Arrived":"Sleeping in bed at home","Officer":"Matthew Kinne","Police_Department":"Oxford Police Department","Armed_Before_Police_Arrived":"N","Officer_Charged":"Y","Officer_Race_Ethnicity":"White"},{"Victim_Name":"Michael Lorenzo Dean","Age":28,"Race_Ethnicity":"Black","City":"Temple","State":"TX","Date_of_Death":"12-02-2020","Before_Police_Arrived":"Driving in car on road","Officer":"Carmen DeCruz","Police_Department":"Temple Police Department","Armed_Before_Police_Arrived":"N","Officer_Charged":"Y","Officer_Race_Ethnicity":"Latinx"},{"Victim_Name":"George Floyd","Age":46,"Race_Ethnicity":"Black","City":"Minneapolis","State":"MN","Date_of_Death":"05-25-2020","Before_Police_Arrived":"Driving in car from store","Officer":"Derek Chauvin","Police_Department":"Minneapolis Police Department","Armed_Before_Police_Arrived":"N","Officer_Charged":"Y","Officer_Race_Ethnicity":"White"},{"Victim_Name":"Atatiana Jefferson","Age":28,"Race_Ethnicity":"Black","City":"Fort Worth","State":"TX","Date_of_Death":"10-12-2019","Before_Police_Arrived":"Babysitting nephew at home","Officer":"Aaron Dean","Police_Department":"Fort Worth Police Department","Armed_Before_Police_Arrived":"Y","Officer_Charged":"Y","Officer_Race_Ethnicity":"White"},{"Victim_Name":"Sean Monterrosa","Age":22,"Race_Ethnicity":"Latinx","City":"Vallejo","State":"CA","Date_of_Death":"06-02-2020","Before_Police_Arrived":"In Walgreens parking lot","Officer":"Jarrett Tonn","Police_Department":"Vallejo Police Department","Armed_Before_Police_Arrived":"N","Officer_Charged":"N","Officer_Race_Ethnicity":"White"},{"Victim_Name":"Eric Reason","Age":38,"Race_Ethnicity":"Black","City":"Vallejo","State":"CA","Date_of_Death":"11-10-2019","Before_Police_Arrived":"In JJ's Fish and Chicken parking lot","Officer":"Virgil Thomas","Police_Department":"Richmond Police Department","Armed_Before_Police_Arrived":"Y","Officer_Charged":"N","Officer_Race_Ethnicity":"Black"},{"Victim_Name":"Breonna Taylor","Age":26,"Race_Ethnicity":"Black","City":"Louisville","State":"KY","Date_of_Death":"03-13-2020","Before_Police_Arrived":"Sleeping in bed at home","Officer":"Brett Hankison","Police_Department":"Louisville Metro Police Department","Armed_Before_Police_Arrived":"N","Officer_Charged":"N","Officer_Race_Ethnicity":"White"}]
```

### Unstructured data
Unstructured data is often unorganized and in human readable text. What I mean by unstructured data is text data. In text - when we think of documents, papers, journals, books - we think of the writing as structured with an introduction, main thesis, supporting paragraphs, and a conclusion. We often think of the writing as being well-organized with logical flow of ideas, correct punctuation, and limited spelling and grammatical errors. These are true of well-written text in paper or digital copy. But imagine this book or article existing as a dataset. How would you organize it? Would there be records and fields? What would the main information consist of? Any delimiters?

These questions are not easy to answer and are equally difficult for a computer to figure out. Yet, text is so readily available for analysis that new approaches in text mining and natural language processing are ripe for the taking.

Below are two texts.

    Angela Davis from the Women's March (2017) transcribed in The Guardian. "We recognize that we are collective agents of history and that history cannot be deleted like web pages. We know that we gather this afternoon on indigenous land and we follow the lead of the first peoples who despite massive genocidal violence have never relinquished the struggle for land, water, culture, their people. We especially salute today the Standing Rock Sioux. The freedom struggles of black people that have shaped the very nature of this country's history cannot be deleted with the sweep of a hand. We cannot be made to forget that black lives do matter. This is a country anchored in slavery and colonialism, which means for better or for worse the very history of the United States is a history of immigration and enslavement. Spreading xenophobia, hurling accusations of murder and rape and building walls will not erase history."

    Marsha P. Johnson from Kasino, Michael (2012). Pay It No Mind - The Life and Times of Marsha P. Johnson (Documentary film). "How many people have died for these two little statues to be put in the park to recognize gay people? How many years does it take for people to see that we're all brothers and sisters and human beings in the human race? I mean how many years does it take for people to see that we're all in this rat race together."

Typically, we can create a structure that is more friendly and organized for computers to handle. Often, the records (i.e. rows) are the different texts or documents (speeches, emails, tweets, articles) in plain text format. If there are any fields included in the text data, then they may be the document source, ID of the document, published date, etc. If the text could be separated into individual words such that each row is a new unique term and place the different documents in the columns, then we may call this structure a term-document matrix (TDM).  


***


## Importing data
Data can be accessed with R no matter the location. R has several datasets internally stored. We can see the list of them using

```{r}
data()
```

We should be able to query using the help function `?` for any of R’s internal datasets for more information. Some datasets are stored within packages. Thus if we want to access them, we need to call upon that specific package.
```{r}
data(package="MASS")
```

The bulk of what you will handle in life as statisticians will be external datasets. There are several ways to access and import external data: read.table, read.csv, and using the tidyverse package.

### using `read.table()`
One of R's default functions for accessing data in general, especially data with tabs or spaces as delimiters or separators. We usually need to supply the file location, whether the data has column names in its first row, and the separator. Let's read in a local data file. First, download the [brain.txt](https://uofi.box.com/shared/static/cyczwbfxpllw7f5jt5qoip6mt1578cke.txt) to your local computer.

```
##run this but change the file location
read.table( "C:/Users/CKinson/Downloads/brain.txt" ,header=TRUE, sep="\t")
```


### using `read.csv()`

One of R's default functions for accessing data with commas as delimiters or separators. It has the same functionality as `read.table`. We supply the file location (and file name) and whether the data has column names in its first row. Let's read in a local data file. First, download the [brain.csv](https://uofi.box.com/shared/static/4v7q5rzxsrceeuzioya99zn2z85mcfno.csv) to your local computer.

```
##run this but change the file location
read.csv( "C:/Users/CKinson/Downloads/brain.csv" ,header=TRUE)
```

With the most up-to-date version of R `r version`, we can import data with R's default functions using a URL for the data instead of having to download the data and locate it.

```
##run this but change the file location
read.csv("https://uofi.box.com/shared/static/4v7q5rzxsrceeuzioya99zn2z85mcfno.csv")
```

***Remember that using base R functions results in data.frames as the data objects, not tibbles. Thus the data frames will have rownames by default unless we specify otherwise.***


***


## Data wrangling
Data wrangling is the set of procedures and tasks for cleaning and managing data so that the data can be analyzed easily. It is a crucial and time-consuming aspect of data analysis work. In this course, we are going to opt for a mixture of standard R functionality (Week 8) as well as **tidyverse** functionality (Week 9) to wrangle data in a neat and useful manner.

We're going to explore 5 common actions for data wrangling. Let's show some examples with the **SBA Loans Data** from previous class.

Here's how we can import an old version of the SBA Loans Data. Using `read.csv()` will take several minutes to import a large dataset.
```{r importing}
Sys.time()
sba <- read.csv("https://uofi.box.com/shared/static/vi37omgitiaa2yyplrom779qvwk1g14x.csv")
Sys.time()
```

Next, we create a subset of the data which is much smaller than the original, print the first few rows of the subset, and remove the original larger data set.
```{r cleaning}
set.seed(448)
SBA <- sba[sample(1:dim(sba)[1],200),] #randomized subset of 200 rows
head(SBA, 10) #first 10 rows
rm(sba) #remove the original large data file
```

When we check the mode of some of the columns in the SBA data, we notice that several columns represent dollar amounts yet have been automatically imported as character type. We have already learned about coercion and the pitfalls of coercion with data.frames. There is one big issue with attempting to coerce the dollar amounts in these columns: the literal dollar sign in each row preceding the number. Thus we'll briefly mention character manipulation.


### String manipulation (preview of regular expressions)
Strings are characters or sequences of characters. We can work with strings to wrangle them into something we need. The more detailed discussion of this is regular expression and stringr package in the tidyverse. For now, we will focus on the specific SBA data application.

We need to remove the dollar signs in order to properly coerce the columns representing dollar amounts to be numeric. We'll use the double escape character `\\` before the dollar character as our pattern to match; `\\$`. The second argument is what we want to replace the dollar sign with; `""` since we just want to remove the dollar sign from the values.
```{r}
test1 <- gsub("\\$","",SBA$DisbursementGross[1:10]) #just trying it out for the first 10 values

as.numeric(test1) #checking coercion
```

After successfully using `gsub()` to replace the dollar characters with nothing, we see another issue that is going to prevent us from coercing the amounts to be numeric. The space after the 00. Let's reuse the `gsub()` function but with the special space character `\\s` as the pattern to match and remove.
```{r}
test2 <- gsub("\\s","",SBA$DisbursementGross[1:10]) #just trying it out for the first 10 values

as.numeric(test2)
```

Now, we can put these two ideas together in one single pattern for removal and replacement.
```{r}
test3 <- gsub("\\s||\\$","",SBA$DisbursementGross[1:10]) #just trying it out for the first 10 values

as.numeric(test3)
```

Still, those pesky commas are preventing us from moving forward with coercion to numeric mode.
```{r}
test4 <- gsub("\\s||\\$||\\,","",SBA$DisbursementGross[1:10]) #just trying it out for the first 10 values

as.numeric(test4)
```

Success!


### Filtering
We can subset observations based on their values in R using indexing, the which function, and logical operators. This type of subsetting allows us to only show observations that satisfy a particular condition. **The `subset()` function is never allowed in this course.**
```{r filtering}
head(SBA[which(SBA$State=="CA"),])

head(SBA[which(SBA$State=="CA" & SBA$City=="LOS ANGELES"),])

head(SBA[which(SBA$State=="CA" | SBA$State=="GA"),]) #CA or GA

head(SBA[which(SBA$State=="CA" & SBA$State=="GA"),]) #??? No business can be in two states simultaneously
```


### Arranging
This action sorts the data by a particular set of columns. We can sort items in ascending (default) or descending order for a particular column. And we can do this for more than one column at once.
```{r arranging}
head(SBA[order(SBA$State),])

head(SBA[order(SBA$NoEmp, decreasing = TRUE),])

SBA2 <- SBA[order(SBA$State, SBA$NoEmp, decreasing = c(FALSE, TRUE)),]
head(SBA2)
```


### Selecting
This action describes keeping or dropping variables or columns from a dataset; indexing is our friend. We might also **rename** variables or columns via overwriting an existing column name; use the assignment operator `<-`.
```{r selecting}
SBA[, c("State", "NoEmp")] #keep columns by name

SBA[, c(4, 12)] #keep columns by number

SBA[, 1:(ncol(SBA)-1)] #keep columns by number with sequence

SBA[, -c(4,12)] #drop columns by number

SBA$DisbursementGross <- as.numeric(gsub("\\s||\\$||\\,","",SBA$DisbursementGross))
 #this is a permanent new variable
```


### Mutating
Mutating a data set is the act of creating new variables. With base R functionality, mutating is accomplished through the assignment operator `<-`.
```{r mutating}
SBA$Portion <- as.numeric(gsub("\\s||\\$||\\,","",SBA$SBA_Appv))/as.numeric(gsub("\\s||\\$||\\,","",SBA$GrAppv))
SBA$LogDisbursementGross <- log(SBA$DisbursementGross)
head(SBA[,c("Portion","LogDisbursementGross")])
```


### Summarizing
We can create grouped summaries of data by calculating a summary value (frequency, mean, median, etc.) for all members within a group. Ideally, we want the result to be a data frame or other recursive object when possible. With base R, we may have to use loops and conditional execution to achieve the grouped summaries.
```{r summarising}
g <- sort(unique(SBA$State))
gs <- rep(0,length(g))
for (i in 1:length(gs)){
 gs[i] <- mean(SBA[SBA$State==g[i],"DisbursementGross"])
}
data.frame(state = g, avg_disbursementgross = gs, row.names = NULL)
```


### Combining
What happens when you need to work with multiple datasets at once? What happens when the one dataset you have is not enough information? Where do you get the additional information? Combining data sets is a very useful data wrangling operation. Grabbing information from another dataset and adding it to your current one potentially increases your information. Combining data could mean different things in various disciplines or the same thing with different terms such as concatenating, merging, binding, appending, or joining.

In R, concatenating is the act of combining objects or strings together and is typically done with `c()` or `paste()`.

In R, binding (or appending) is the act of combining two or more objects by stacking one on top of the other such as `rbind()` in R or stacking one next to the other such as `cbind()` in R.

Merging (or joining) usually implies combining two or more objects with different columns of information into one single object. This merging would require each of the different data objects to have one column in common with a unique identifying information such as an ID variable or geographic location. There are at least 3 situations that can occur when merging objects. 

1. Observations in the two (or more) separate objects could not match each other.

**Data 1**  

ID | Salary
---|---
A | $10K
B | $11K
D | $12K

**Data 2**  

ID | Number
---|---
C | 2175551234
E | 2175551235
F | 2175551236

**Merged Data**  

ID | Salary | Number
---|---|---
A | $10K |
B | $11K |
D | $12K |
C |  | 2175551234
E |  | 2175551235
F |  | 2175551236

2. Observations in the two (or more) separate objects could match each other one-to-one.

**Data 1**  

ID | Salary
---|---
A | $10K
B | $11K
D | $12K

**Data 2**  

ID | Number
---|---
A | 2175551214
B | 2175551224
D | 2175551244

**Merged Data**  

ID | Salary | Number
---|---|---
A | $10K | 2175551214
B | $11K | 2175551224
D | $12K | 2175551244

3. Observations in the two (or more) separate objects could match each other one-to-many (or many-to-one).

**Data 1**  

ID | Salary
---|---
A | $10K
D | $12K

**Data 2** 

ID | Number
---|---
A | 2175551214
A | 2175551204
D | 2175551244

**Merged Data**  

ID | Salary | Number
---|---|---
A | $10K | 2175551214
A | $10K | 2175551204
D | $12K | 2175551244

How we merge (or join) the data depends on which of the three situations is intended for the data we want in the end. Only keeping the matches (#2 and #3 above) could be accomplished using an inner join (`merge(...,all=FALSE)`). Keeping the matches (#2 and #3 above) and non-matches (#1 above) could be accomplished using a full join (`merge(...,all=TRUE)`). Whenever the common column of the different data objects contain the same information but have different column names, the easiest fix is to rename the column in one of the two objects.

The code example below highlights the different meanings for combining data in R coding.

```{r combining}
irisdat1 <- iris[1:100, c(1,4,5)]
irisdat2 <- iris[1:100, c(2,3,5)]
irisdat3 <- iris[101:150, c(2,3,5)]

head(irisdat1)
head(irisdat2)
head(irisdat3)

paste("The iris we love most is the", iris$Species,"species.")[1:10]

head(cbind(irisdat1, irisdat2[,-3]))

head(rbind(irisdat2, irisdat3))

head(merge(irisdat1, irisdat2, by="Species", all=FALSE))

irisdat1$NewSpecies <- paste0(irisdat1$Species, 1:100)
irisdat2$NewSpecies <- paste0(irisdat2$Species, 1:100)
head(merge(irisdat1, irisdat2, by="NewSpecies", all = FALSE))
```
